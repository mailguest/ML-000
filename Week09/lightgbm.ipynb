{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "lightgbm.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "FozVt65SvqeF"
      },
      "source": [
        "import io\n",
        "import multiprocessing\n",
        "from contextlib import redirect_stdout\n",
        "from copy import deepcopy\n",
        "from dataclasses import dataclass, asdict\n",
        "import hyperopt.pyll\n",
        "from hyperopt import fmin, tpe, hp\n",
        "import numpy as np\n",
        "import lightgbm as lgb\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import roc_auc_score\n",
        "import torch\n",
        "import copy\n",
        "\n",
        "cpu_count = 4\n",
        "use_gpu = False\n",
        "\n",
        "@dataclass\n",
        "class LGBOpt:\n",
        "    num_threads: any = hp.choice('num_threads', [cpu_count])\n",
        "    num_leaves: any = hp.choice('num_leaves', [64])\n",
        "    metric: any = hp.choice('metric', ['binary_error'])\n",
        "    num_round: any = hp.choice('num_rounds', [1000])\n",
        "    objective: any = hp.choice('objective', ['binary'])\n",
        "    learning_rate: any = hp.uniform('learning_rate', 0.01, 0.1)\n",
        "    feature_fraction: any = hp.uniform('feature_fraction', 0.5, 1.0)\n",
        "    bagging_fraction: any = hp.uniform('bagging_fraction', 0.8, 1.0)\n",
        "    device_type: any = hp.choice('device_tpye', ['gpu']) if use_gpu else hp.choice('device_type', ['cpu'])\n",
        "    boosting: any = hp.choice('boosting', ['gbdt', 'dart', 'goss'])\n",
        "    extra_trees: any = hp.choice('extra_tress', [False, True])\n",
        "    drop_rate: any = hp.uniform('drop_rate', 0, 0.2)\n",
        "    uniform_drop: any = hp.choice('uniform_drop', [True, False])\n",
        "    lambda_l1: any = hp.uniform('lambda_l1', 0, 10)  # TODO: Check range\n",
        "    lambda_l2: any = hp.uniform('lambda_l2', 0, 10)  # TODO: Check range\n",
        "    min_gain_to_split: any = hp.uniform('min_gain_to_split', 0, 1)  # TODO: Check range\n",
        "    min_data_in_bin = hp.choice('min_data_in_bin', [3, 5, 10, 15, 20, 50])\n",
        "\n",
        "    @staticmethod\n",
        "    def get_common_params():\n",
        "        return {'num_thread': 4, 'num_leaves': 12, 'metric': 'binary', 'objective': 'binary',\n",
        "                'num_round': 1000, 'learning_rate': 0.01, 'feature_fraction': 0.8, 'bagging_fraction': 0.8}\n",
        "\n",
        "class FitterBase(object):\n",
        "    def __init__(self, label, metric, max_eval=100, opt=None):\n",
        "        self.label = label\n",
        "        self.metric = metric\n",
        "        self.opt_params = dict()\n",
        "        self.max_eval = max_eval\n",
        "        self.opt = opt\n",
        "\n",
        "    def get_loss(self, y, y_pred):\n",
        "        if self.metric == 'error':\n",
        "            return 1 - accuracy_score(y, y_pred)\n",
        "        elif self.metric == 'precision':\n",
        "            return 1 - precision_score(y, y_pred)\n",
        "        elif self.metric == 'recall':\n",
        "            return 1 - recall_score(y, y_pred)\n",
        "        elif self.metric == 'macro_f1':\n",
        "            return 1 - f1_score(y, y_pred, average='macro')\n",
        "        elif self.metric == 'micro_f1':\n",
        "            return 1 - f1_score(y, y_pred, average='micro')\n",
        "        elif self.metric == 'auc':  # TODO: Add a warning checking if y_predict is all [0, 1], it should be probability\n",
        "            return 1 - roc_auc_score(y, y_pred)\n",
        "        else:\n",
        "            raise Exception(\"Not implemented yet.\")\n",
        "\n",
        "class LGBFitter(FitterBase):\n",
        "    def __init__(self, label='label', metric='error', opt: LGBOpt = None, max_eval=100):\n",
        "        super(LGBFitter, self).__init__(label, metric, max_eval)\n",
        "        if opt is not None:\n",
        "            self.opt = opt\n",
        "        else:\n",
        "            self.opt = LGBOpt()\n",
        "        self.best_round = None\n",
        "        self.clf = None\n",
        "\n",
        "    def train(self, train_df, eval_df, params=None, use_best_eval=True):\n",
        "        self.best_round = None\n",
        "        dtrain = lgb.Dataset(train_df.drop(columns=[self.label]), train_df[self.label])\n",
        "        deval = lgb.Dataset(eval_df.drop(columns=[self.label]), eval_df[self.label])\n",
        "        evallist = [dtrain, deval]\n",
        "        if params is None:\n",
        "            use_params = deepcopy(self.opt_params)\n",
        "        else:\n",
        "            use_params = deepcopy(params)\n",
        "\n",
        "        num_round = use_params.pop('num_round')\n",
        "        if use_best_eval:\n",
        "            with io.StringIO() as buf, redirect_stdout(buf):\n",
        "                self.clf = lgb.train(use_params, dtrain, num_round, valid_sets=evallist)\n",
        "                output = buf.getvalue().split(\"\\n\")\n",
        "            min_error = np.inf\n",
        "            min_index = 0\n",
        "            for idx in range(len(output) - 1):\n",
        "                if len(output[idx].split(\"\\t\")) == 3:\n",
        "                    temp = float(output[idx].split(\"\\t\")[2].split(\":\")[1])\n",
        "                    if min_error > temp:\n",
        "                        min_error = temp\n",
        "                        min_index = int(output[idx].split(\"\\t\")[0][1:-1])\n",
        "            print(\"The minimum is attained in round %d\" % (min_index + 1))\n",
        "            self.best_round = min_index + 1\n",
        "            return output\n",
        "        else:\n",
        "            with io.StringIO() as buf, redirect_stdout(buf):\n",
        "                self.clf = lgb.train(use_params, dtrain, num_round, valid_sets=evallist)\n",
        "                output = buf.getvalue().split(\"\\n\")\n",
        "            self.best_round = num_round\n",
        "            return output\n",
        "\n",
        "    def search(self, train_df, eval_df, use_best_eval=True):\n",
        "        self.opt_params = dict()\n",
        "\n",
        "        def train_impl(params):\n",
        "            self.train(train_df, eval_df, params, use_best_eval)\n",
        "            if self.metric == 'auc':\n",
        "                y_pred = self.clf.predict(eval_df.drop(columns=[self.label]), num_iteration=self.best_round)\n",
        "            else:\n",
        "                y_pred = (self.clf.predict(eval_df.drop(columns=[self.label]),\n",
        "                                           num_iteration=self.best_round) > 0.5).astype(int)\n",
        "            return self.get_loss(eval_df[self.label], y_pred)\n",
        "\n",
        "        self.opt_params = fmin(train_impl, asdict(self.opt), algo=tpe.suggest, max_evals=self.max_eval)\n",
        "\n",
        "    def search_k_fold(self, k_fold, data, use_best_eval=True):\n",
        "        self.opt_params = dict()\n",
        "\n",
        "        def train_impl_nfold(params):\n",
        "            loss = list()\n",
        "            for train_id, eval_id in k_fold.split(data):\n",
        "                train_df = data.loc[train_id]\n",
        "                eval_df = data.loc[eval_id]\n",
        "                self.train(train_df, eval_df, params, use_best_eval)\n",
        "                if self.metric == 'auc':\n",
        "                    y_pred = self.clf.predict(eval_df.drop(columns=[self.label]), num_iteration=self.best_round)\n",
        "                else:\n",
        "                    y_pred = (self.clf.predict(eval_df.drop(columns=[self.label]),\n",
        "                                               num_iteration=self.best_round) > 0.5).astype(int)\n",
        "                loss.append(self.get_loss(eval_df[self.label], y_pred))\n",
        "            return np.mean(loss)\n",
        "\n",
        "        self.opt_params = fmin(train_impl_nfold, asdict(self.opt), algo=tpe.suggest, max_evals=self.max_eval)\n",
        "\n",
        "    def train_k_fold(self, k_fold, train_data, test_data, params=None, drop_test_y=True, use_best_eval=True):\n",
        "        acc_result = list()\n",
        "        train_pred = np.empty(train_data.shape[0])\n",
        "        test_pred = np.empty(test_data.shape[0])\n",
        "        if drop_test_y:\n",
        "            dtest = test_data.drop(columns=self.label)\n",
        "        else:\n",
        "            dtest = test_data\n",
        "\n",
        "        models = list()\n",
        "        for train_id, eval_id in k_fold.split(train_data):\n",
        "            train_df = train_data.loc[train_id]\n",
        "            eval_df = train_data.loc[eval_id]\n",
        "            self.train(train_df, eval_df, params, use_best_eval)\n",
        "            models.append(copy.deepcopy(self.clf))\n",
        "            train_pred[eval_id] = self.clf.predict(eval_df.drop(columns=self.label), num_iteration=self.best_round)\n",
        "            if self.metric == 'auc':\n",
        "                y_pred = self.clf.predict(eval_df.drop(columns=[self.label]), num_iteration=self.best_round)\n",
        "            else:\n",
        "                y_pred = (self.clf.predict(eval_df.drop(columns=[self.label]),\n",
        "                                           num_iteration=self.best_round) > 0.5).astype(int)\n",
        "            acc_result.append(self.get_loss(eval_df[self.label], y_pred))\n",
        "            test_pred += self.clf.predict(dtest, num_iteration=self.best_round)\n",
        "        test_pred /= k_fold.n_splits\n",
        "        return train_pred, test_pred, acc_result, models"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "40Wy5fC5RkAX"
      },
      "source": [
        "# 先导入数据并分析数据"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GWZ1r6jMuTNk"
      },
      "source": [
        "import pandas as pd\n",
        "import lightgbm as lgb\n",
        "from sklearn.model_selection import KFold\n",
        "\n",
        "path = '/content/drive/MyDrive/geek/06/final/'\n",
        "train_data = pd.read_csv(path + 'train_final.csv', engine='python')\n",
        "test_data = pd.read_csv(path + 'test_final.csv', engine='python')"
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252
        },
        "id": "5w5syA3mXOtM",
        "outputId": "c9aa9018-8325-4c0d-9e55-bee33a4329d8"
      },
      "source": [
        "train_data.head()"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>continuous_annual_inc</th>\n",
              "      <th>continuous_annual_inc_joint</th>\n",
              "      <th>continuous_delinq_2yrs</th>\n",
              "      <th>continuous_dti</th>\n",
              "      <th>continuous_dti_joint</th>\n",
              "      <th>continuous_fico_range_high</th>\n",
              "      <th>continuous_fico_range_low</th>\n",
              "      <th>continuous_funded_amnt</th>\n",
              "      <th>continuous_funded_amnt_inv</th>\n",
              "      <th>continuous_inq_last_6mths</th>\n",
              "      <th>continuous_installment</th>\n",
              "      <th>continuous_int_rate</th>\n",
              "      <th>continuous_last_fico_range_high</th>\n",
              "      <th>continuous_last_fico_range_low</th>\n",
              "      <th>continuous_loan_amnt</th>\n",
              "      <th>loan_status</th>\n",
              "      <th>continuous_mths_since_last_delinq</th>\n",
              "      <th>continuous_mths_since_last_major_derog</th>\n",
              "      <th>continuous_mths_since_last_record</th>\n",
              "      <th>continuous_open_acc</th>\n",
              "      <th>continuous_pub_rec</th>\n",
              "      <th>discrete_addr_state_1_one_hot</th>\n",
              "      <th>discrete_addr_state_2_one_hot</th>\n",
              "      <th>discrete_addr_state_3_one_hot</th>\n",
              "      <th>discrete_addr_state_4_one_hot</th>\n",
              "      <th>discrete_addr_state_5_one_hot</th>\n",
              "      <th>discrete_addr_state_6_one_hot</th>\n",
              "      <th>discrete_addr_state_7_one_hot</th>\n",
              "      <th>discrete_addr_state_8_one_hot</th>\n",
              "      <th>discrete_addr_state_9_one_hot</th>\n",
              "      <th>discrete_addr_state_10_one_hot</th>\n",
              "      <th>discrete_addr_state_11_one_hot</th>\n",
              "      <th>discrete_addr_state_12_one_hot</th>\n",
              "      <th>discrete_addr_state_13_one_hot</th>\n",
              "      <th>discrete_addr_state_14_one_hot</th>\n",
              "      <th>discrete_addr_state_15_one_hot</th>\n",
              "      <th>discrete_addr_state_16_one_hot</th>\n",
              "      <th>discrete_addr_state_17_one_hot</th>\n",
              "      <th>discrete_addr_state_18_one_hot</th>\n",
              "      <th>discrete_addr_state_19_one_hot</th>\n",
              "      <th>...</th>\n",
              "      <th>discrete_purpose_11_one_hot</th>\n",
              "      <th>discrete_purpose_12_one_hot</th>\n",
              "      <th>discrete_pymnt_plan_1_one_hot</th>\n",
              "      <th>discrete_sub_grade_1_one_hot</th>\n",
              "      <th>discrete_sub_grade_2_one_hot</th>\n",
              "      <th>discrete_sub_grade_3_one_hot</th>\n",
              "      <th>discrete_sub_grade_4_one_hot</th>\n",
              "      <th>discrete_sub_grade_5_one_hot</th>\n",
              "      <th>discrete_sub_grade_6_one_hot</th>\n",
              "      <th>discrete_sub_grade_7_one_hot</th>\n",
              "      <th>discrete_sub_grade_8_one_hot</th>\n",
              "      <th>discrete_sub_grade_9_one_hot</th>\n",
              "      <th>discrete_sub_grade_10_one_hot</th>\n",
              "      <th>discrete_sub_grade_11_one_hot</th>\n",
              "      <th>discrete_sub_grade_12_one_hot</th>\n",
              "      <th>discrete_sub_grade_13_one_hot</th>\n",
              "      <th>discrete_sub_grade_14_one_hot</th>\n",
              "      <th>discrete_sub_grade_15_one_hot</th>\n",
              "      <th>discrete_sub_grade_16_one_hot</th>\n",
              "      <th>discrete_sub_grade_17_one_hot</th>\n",
              "      <th>discrete_sub_grade_18_one_hot</th>\n",
              "      <th>discrete_sub_grade_19_one_hot</th>\n",
              "      <th>discrete_sub_grade_20_one_hot</th>\n",
              "      <th>discrete_sub_grade_21_one_hot</th>\n",
              "      <th>discrete_sub_grade_22_one_hot</th>\n",
              "      <th>discrete_sub_grade_23_one_hot</th>\n",
              "      <th>discrete_sub_grade_24_one_hot</th>\n",
              "      <th>discrete_sub_grade_25_one_hot</th>\n",
              "      <th>discrete_sub_grade_26_one_hot</th>\n",
              "      <th>discrete_sub_grade_27_one_hot</th>\n",
              "      <th>discrete_sub_grade_28_one_hot</th>\n",
              "      <th>discrete_sub_grade_29_one_hot</th>\n",
              "      <th>discrete_sub_grade_30_one_hot</th>\n",
              "      <th>discrete_sub_grade_31_one_hot</th>\n",
              "      <th>discrete_sub_grade_32_one_hot</th>\n",
              "      <th>discrete_sub_grade_33_one_hot</th>\n",
              "      <th>discrete_sub_grade_34_one_hot</th>\n",
              "      <th>discrete_sub_grade_35_one_hot</th>\n",
              "      <th>discrete_term_1_one_hot</th>\n",
              "      <th>discrete_term_2_one_hot</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>55000.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.91</td>\n",
              "      <td>NaN</td>\n",
              "      <td>679.0</td>\n",
              "      <td>675.0</td>\n",
              "      <td>3600.0</td>\n",
              "      <td>3600.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>123.03</td>\n",
              "      <td>13.99</td>\n",
              "      <td>564.0</td>\n",
              "      <td>560.0</td>\n",
              "      <td>3600.0</td>\n",
              "      <td>1</td>\n",
              "      <td>30.0</td>\n",
              "      <td>30.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>7.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>65000.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>16.06</td>\n",
              "      <td>NaN</td>\n",
              "      <td>719.0</td>\n",
              "      <td>715.0</td>\n",
              "      <td>24700.0</td>\n",
              "      <td>24700.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>820.28</td>\n",
              "      <td>11.99</td>\n",
              "      <td>699.0</td>\n",
              "      <td>695.0</td>\n",
              "      <td>24700.0</td>\n",
              "      <td>1</td>\n",
              "      <td>6.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>22.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>63000.0</td>\n",
              "      <td>71000.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>10.78</td>\n",
              "      <td>13.85</td>\n",
              "      <td>699.0</td>\n",
              "      <td>695.0</td>\n",
              "      <td>20000.0</td>\n",
              "      <td>20000.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>432.66</td>\n",
              "      <td>10.78</td>\n",
              "      <td>704.0</td>\n",
              "      <td>700.0</td>\n",
              "      <td>20000.0</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>6.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>104433.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>25.37</td>\n",
              "      <td>NaN</td>\n",
              "      <td>699.0</td>\n",
              "      <td>695.0</td>\n",
              "      <td>10400.0</td>\n",
              "      <td>10400.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>289.91</td>\n",
              "      <td>22.45</td>\n",
              "      <td>704.0</td>\n",
              "      <td>700.0</td>\n",
              "      <td>10400.0</td>\n",
              "      <td>1</td>\n",
              "      <td>12.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>12.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>34000.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>10.20</td>\n",
              "      <td>NaN</td>\n",
              "      <td>694.0</td>\n",
              "      <td>690.0</td>\n",
              "      <td>11950.0</td>\n",
              "      <td>11950.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>405.18</td>\n",
              "      <td>13.44</td>\n",
              "      <td>759.0</td>\n",
              "      <td>755.0</td>\n",
              "      <td>11950.0</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>5.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 146 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   continuous_annual_inc  ...  discrete_term_2_one_hot\n",
              "0                55000.0  ...                        0\n",
              "1                65000.0  ...                        0\n",
              "2                63000.0  ...                        1\n",
              "3               104433.0  ...                        1\n",
              "4                34000.0  ...                        0\n",
              "\n",
              "[5 rows x 146 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZlZvHsfqMbSa"
      },
      "source": [
        "# EDA\r\n",
        "\r\n",
        "模型最低成功概率为：79.576%"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NPyoW1jwMYFR",
        "outputId": "a6473e64-8f51-4da5-8707-247417d90eaa"
      },
      "source": [
        "y = 'loan_status'\r\n",
        "y_train_date = train_data[y]\r\n",
        "y_train_date.value_counts() / y_train_date.count()"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1    0.79576\n",
              "0    0.20424\n",
              "Name: loan_status, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4v2qcafKOE3g"
      },
      "source": [
        "连续变量、离散变量分析"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nVWBPHvPRh7g",
        "outputId": "8603d375-002c-4049-cf2b-a778e3b3e3bf"
      },
      "source": [
        "continuous_train_data = train_data.loc[:, [x for x in train_data.columns if 'continuous' in x]]\r\n",
        "discrete_train_data = train_data.loc[:, [x for x in train_data.columns if 'discrete' in x]]\r\n",
        "\r\n",
        "len(continuous_train_data.columns) + len(discrete_train_data.columns) + 1 == len(train_data.columns)"
      ],
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IggkzpdKybRV"
      },
      "source": [
        "# ROUND 1 原始值"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WGtTznoYuhND",
        "outputId": "04624d71-6b2b-43e5-edc1-605dc5995296"
      },
      "source": [
        "params1 = {'num_thread': 4, \n",
        "      'num_leaves': 12,\n",
        "      'metric': 'binary',\n",
        "      'objective': 'binary',\n",
        "      'num_round': 2000,\n",
        "      'learning_rate': 0.02,\n",
        "      'feature_fraction': 0.8,\n",
        "      'bagging_fraction': 0.8}\n",
        "result_map1 = fitter.train_k_fold(kfold, train_data, test_data, params = params1)\n",
        "result_map1[2]"
      ],
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The minimum is attained in round 413\n",
            "The minimum is attained in round 578\n",
            "The minimum is attained in round 397\n",
            "The minimum is attained in round 623\n",
            "The minimum is attained in round 329\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.07179999999999997,\n",
              " 0.08140000000000003,\n",
              " 0.08330000000000004,\n",
              " 0.0837,\n",
              " 0.08089999999999997]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 100
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CX2p6LTPdGgd"
      },
      "source": [
        "# ROUND 2 使用连续变量看看效果"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Y6ku60EdLjj",
        "outputId": "9f71d56b-2bca-4c87-e2a4-a16887bf9ec7"
      },
      "source": [
        "params2 = {'num_thread': 4, \r\n",
        "      'num_leaves': 12,\r\n",
        "      'metric': 'binary',\r\n",
        "      'objective': 'binary',\r\n",
        "      'num_round': 2000,\r\n",
        "      'learning_rate': 0.02,\r\n",
        "      'feature_fraction': 0.8,\r\n",
        "      'bagging_fraction': 0.8}\r\n",
        "\r\n",
        "result_map2 = fitter.train_k_fold(kfold, pd.concat([continuous_train_data, y_train_date], axis=1), test_data, params = params2)\r\n",
        "result_map2[2]"
      ],
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The minimum is attained in round 663\n",
            "The minimum is attained in round 713\n",
            "The minimum is attained in round 607\n",
            "The minimum is attained in round 520\n",
            "The minimum is attained in round 500\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.07310000000000005,\n",
              " 0.08020000000000005,\n",
              " 0.0857,\n",
              " 0.08479999999999999,\n",
              " 0.08120000000000005]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A0rBtVYkf_0j"
      },
      "source": [
        "# ROUND 3 使用离散变量看看效果"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L8SofGfxeY_P",
        "outputId": "2ebd0775-d383-43ab-fcfc-2c7e124ecfd9"
      },
      "source": [
        "params3 = {'num_thread': 4, \r\n",
        "      'num_leaves': 12,\r\n",
        "      'metric': 'binary',\r\n",
        "      'objective': 'binary',\r\n",
        "      'num_round': 2000,\r\n",
        "      'learning_rate': 0.02,\r\n",
        "      'feature_fraction': 0.8,\r\n",
        "      'bagging_fraction': 0.8}\r\n",
        "\r\n",
        "result_map3 = fitter.train_k_fold(kfold, pd.concat([discrete_train_data, y_train_date], axis=1), test_data, params = params3)\r\n",
        "result_map3[2]"
      ],
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The minimum is attained in round 483\n",
            "The minimum is attained in round 294\n",
            "The minimum is attained in round 459\n",
            "The minimum is attained in round 405\n",
            "The minimum is attained in round 276\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.18910000000000005,\n",
              " 0.20709999999999995,\n",
              " 0.19789999999999996,\n",
              " 0.20750000000000002,\n",
              " 0.1965]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "avRJvBlKhBQq"
      },
      "source": [
        "# ROUND 4 使用量数据调整参数"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t68Eo8wPgHov",
        "outputId": "d93c0041-5bb5-42f4-848c-571dd0e1f7c8"
      },
      "source": [
        "params4 = {'num_thread': 5, \r\n",
        "      'num_leaves': 10,\r\n",
        "      'metric': 'binary',\r\n",
        "      'objective': 'binary',\r\n",
        "      'num_round': 1500,\r\n",
        "      'learning_rate': 0.2,\r\n",
        "      'feature_fraction': 0.9,\r\n",
        "      'bagging_fraction': 0.9}\r\n",
        "result_map4 = fitter.train_k_fold(kfold, train_data, test_data, params = params4)\r\n",
        "result_map4[2]"
      ],
      "execution_count": 125,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The minimum is attained in round 52\n",
            "The minimum is attained in round 29\n",
            "The minimum is attained in round 31\n",
            "The minimum is attained in round 38\n",
            "The minimum is attained in round 31\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.0726,\n",
              " 0.08099999999999996,\n",
              " 0.08389999999999997,\n",
              " 0.08499999999999996,\n",
              " 0.08009999999999995]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 125
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HudD-P24hSAn",
        "outputId": "1aee9daa-70b1-4b4e-cc2d-edec0b60c4f3"
      },
      "source": [
        "# train_pred, test_pred, acc_result, models\r\n",
        "print(f\"result_map1 = {result_map1[2]}\")\r\n",
        "print(f\"result_map2 = {result_map2[2]}\")\r\n",
        "print(f\"result_map3 = {result_map3[2]}\")\r\n",
        "print(f\"result_map4 = {result_map4[2]}\")"
      ],
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "result_map1 = [0.07179999999999997, 0.08140000000000003, 0.08330000000000004, 0.0837, 0.08089999999999997]\n",
            "result_map2 = [0.07310000000000005, 0.08020000000000005, 0.0857, 0.08479999999999999, 0.08120000000000005]\n",
            "result_map3 = [0.18910000000000005, 0.20709999999999995, 0.19789999999999996, 0.20750000000000002, 0.1965]\n",
            "result_map4 = [0.0726, 0.08099999999999996, 0.08389999999999997, 0.08499999999999996, 0.08009999999999995]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iw6VINR_k3dx"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}